{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Notebook for saving the model preditions over many images in a folder into .npz format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"../..\")\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"src\"))\n",
    "\n",
    "from src.util import DATA_DIR, MODEL_DIR\n",
    "import src.datasets.transforms as T\n",
    "from src.main import build_model_main\n",
    "from src.util.slconfig import SLConfig\n",
    "from src.datasets import build_dataset\n",
    "from src.util.visualizer import COCOVisualizer\n",
    "from src.util import box_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Finding model and input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES TO CHANGE\n",
    "model_name = \"main_model\"\n",
    "epoch = '0036'\n",
    "dataset_name = \"eida_dataset\"\n",
    "extension = \"jpg\"\n",
    "\n",
    "model_folder = MODEL_DIR / model_name\n",
    "model_config_path = f\"{model_folder}/config_cfg.py\"\n",
    "model_checkpoint_path = f\"{model_folder}/checkpoint{epoch}.pth\"\n",
    "\n",
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.device = 'cuda' \n",
    "args.num_select = 200\n",
    "\n",
    "corpus_folder = DATA_DIR / dataset_name\n",
    "image_paths = glob.glob(f\"{corpus_folder}/images/*.{extension}\")\n",
    "npz_dir = DATA_DIR / dataset_name / f\"npz_preds_{model_name}{epoch}\"\n",
    "\n",
    "os.makedirs(npz_dir) \n",
    "# os.makedirs(npz_dir, exist_ok=True)  # If you are not bothered by overwriting the existing folder, uncomment this and comment the above line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, postprocessors = build_model_main(args)\n",
    "checkpoint = torch.load(model_checkpoint_path, map_location='cuda')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set = \"val\"\n",
    "args.dataset_file = 'synthetic'\n",
    "args.mode = \"primitives\"\n",
    "args.relative = False\n",
    "args.common_queries = True\n",
    "args.eval = (image_set == \"val\")\n",
    "args.coco_path = f\"{DATA_DIR}/synthetic_processed\" # the path of coco\n",
    "args.fix_size = False\n",
    "args.batch_size = 1\n",
    "args.boxes_only=False\n",
    "encoder_only = False\n",
    "vslzr = COCOVisualizer()\n",
    "id2name = {0: 'line', 1: 'circle', 2: 'arc'}\n",
    "primitives_to_show = ['line', 'circle', 'arc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_xy(x):\n",
    "    c_x, c_y, w, h = x\n",
    "    x0, y0 = c_x - w / 2, c_y - h / 2\n",
    "    x1, y1 = c_x + w / 2, c_y + h / 2\n",
    "    \n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def circle_to_xy(x):\n",
    "    c_x, c_y, w, h = x\n",
    "    r = (w+h)/4 \n",
    "    return c_x, c_y, r\n",
    "\n",
    "def arc_to_xy(x):\n",
    "    cx, cy, w, h, w_mid, h_mid = x\n",
    "    x0, y0 = cx - w / 2, cy - h / 2\n",
    "    x1, y1 = cx + w / 2, cy + h / 2\n",
    "    x_mid, y_mid = cx + w_mid / 2, cy + h_mid / 2\n",
    "    return x0, y0, x1, y1, x_mid, y_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs_per_class(pred_dict):\n",
    "    mask = pred_dict[\"labels\"] == 0\n",
    "    lines, line_scores = pred_dict[\"parameters\"][mask][:, :4], pred_dict[\"scores\"][mask]\n",
    "    mask = pred_dict[\"labels\"] == 1\n",
    "    circles, circle_scores = pred_dict[\"parameters\"][mask][:, 4:8], pred_dict[\"scores\"][mask],\n",
    "    mask = pred_dict[\"labels\"] == 2\n",
    "    arcs, arc_scores = pred_dict[\"parameters\"][mask][:, 8:14], pred_dict[\"scores\"][mask]\n",
    "    \n",
    "    lines, line_scores = lines.cpu().numpy(), line_scores.cpu().numpy()\n",
    "    circles, circle_scores = circles.cpu().numpy(), circle_scores.cpu().numpy()\n",
    "    arcs, arc_scores = arcs.cpu().numpy(), arc_scores.cpu().numpy()\n",
    "    \n",
    "    lines = np.array([line_to_xy(x) for x in lines])\n",
    "    circles = np.array([circle_to_xy(x) for x in circles])\n",
    "    arcs = np.array([arc_to_xy(x) for x in arcs])\n",
    "    \n",
    "    return lines, line_scores, circles, circle_scores, arcs, arc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_large_arc(rad_angle):\n",
    "    if rad_angle[0] <= np.pi:\n",
    "        return not (rad_angle[0] < rad_angle[1] < (np.pi + rad_angle[0]))\n",
    "    return (rad_angle[0] - np.pi) < rad_angle[1] < rad_angle[0]\n",
    "\n",
    "def find_circle_center(p1, p2, p3):\n",
    "    \"\"\"Circle center from 3 points\"\"\"\n",
    "    # print(p1, p2, p3)\n",
    "    temp = p2[0] * p2[0] + p2[1] * p2[1]\n",
    "    bc = (p1[0] * p1[0] + p1[1] * p1[1] - temp) / 2\n",
    "    cd = (temp - p3[0] * p3[0] - p3[1] * p3[1]) / 2\n",
    "    det = (p1[0] - p2[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p2[1])\n",
    "    if abs(det) < 1.0e-10:\n",
    "        return (None, None)\n",
    "\n",
    "    cx = (bc * (p2[1] - p3[1]) - cd * (p1[1] - p2[1])) / det\n",
    "    cy = ((p1[0] - p2[0]) * cd - (p2[0] - p3[0]) * bc) / det\n",
    "    return np.array([cx, cy])\n",
    "\n",
    "def find_circle_center_arr(p1, p2, p3):\n",
    "    \"\"\"Circle center from 3 points\"\"\"\n",
    "    temp = p2[:, 0] ** 2 + p2[:, 1] ** 2\n",
    "    bc = (p1[:, 0] ** 2 + p1[:, 1] ** 2 - temp) / 2\n",
    "    cd = (temp - p3[:, 0] ** 2 - p3[:, 1] ** 2) / 2\n",
    "    det = (p1[:, 0] - p2[:, 0]) * (p2[:, 1] - p3[:, 1]) - (p2[:, 0] - p3[:, 0]) * (\n",
    "        p1[:, 1] - p2[:, 1]\n",
    "    )\n",
    "\n",
    "    # Handle the case where the determinant is close to zero\n",
    "    mask = np.abs(det) < 1.0e-10\n",
    "    det[mask] = 1.0  # Prevent division by zero\n",
    "    bc[mask] = 0.0  # These arcs will have center at (0, 0)\n",
    "    cd[mask] = 0.0\n",
    "\n",
    "    cx = (bc * (p2[:, 1] - p3[:, 1]) - cd * (p1[:, 1] - p2[:, 1])) / det\n",
    "    cy = ((p1[:, 0] - p2[:, 0]) * cd - (p2[:, 0] - p3[:, 0]) * bc) / det\n",
    "    return np.stack([cx, cy], axis=-1)\n",
    "\n",
    "\n",
    "def get_angles_from_arc_points(p0, p_mid, p1):\n",
    "    arc_center = find_circle_center(p0, p_mid, p1)\n",
    "    arc_center = (arc_center[0], arc_center[1])\n",
    "    start_angle = np.arctan2(p0[1] - arc_center[1], p0[0] - arc_center[0])\n",
    "    end_angle = np.arctan2(p1[1] - arc_center[1], p1[0] - arc_center[0])\n",
    "    mid_angle = np.arctan2(p_mid[1] - arc_center[1], p_mid[0] - arc_center[0])\n",
    "    return start_angle, mid_angle, end_angle, arc_center\n",
    "\n",
    "\n",
    "def get_arc_plot_params(arc):\n",
    "    start_angle, mid_angle, end_angle, arc_center = get_angles_from_arc_points(\n",
    "        arc[:2],\n",
    "        arc[4:],\n",
    "        arc[2:4],\n",
    "    )\n",
    "    # print(start_angle, mid_angle, end_angle)\n",
    "    diameter = 2 * np.linalg.norm(arc[:2] - arc_center)\n",
    "    to_deg = lambda x: (x * 180 / np.pi) % 360\n",
    "    start_angle, mid_angle, end_angle = (\n",
    "        to_deg(start_angle),\n",
    "        to_deg(mid_angle),\n",
    "        to_deg(end_angle),\n",
    "    )\n",
    "    # print(\"angles\", start_angle, mid_angle, end_angle)\n",
    "    return start_angle, mid_angle, end_angle, arc_center, diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpers for removing duplicates\n",
    "Removing immediate duplicates, very small lines, arcs on top of lines and circles (might need to add merging fragmented lines and arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_circles(circle_coords_list, image_size, circle_scores=None):\n",
    "    circle_coords = np.array(circle_coords_list).reshape(-1, 3) # (n_circles, 3)\n",
    "    distances = np.linalg.norm(circle_coords[None, :, :] - circle_coords[:, None, :], axis=-1)\n",
    "    threshold = (image_size[0] + image_size[1]) / 80\n",
    "    mask = distances < threshold\n",
    "    indices_to_remove = np.array([np.sum(row[i+1:]) for i, row in enumerate(mask)])\n",
    "    indices_to_keep = np.where(indices_to_remove == 0)[0]\n",
    "    if circle_scores is not None:\n",
    "        circle_scores = np.array(circle_scores)\n",
    "        return circle_coords_list[indices_to_keep], circle_scores[indices_to_keep]\n",
    "    return circle_coords[indices_to_keep]\n",
    "\n",
    "def remove_duplicate_lines(line_coords_list, image_size, line_scores=None):\n",
    "    line_coords = np.array(line_coords_list).reshape(-1, 4) # (n_lines, 4)\n",
    "    permuted_lines = np.hstack((line_coords[:, 2:4],line_coords[:, 0:2]))\n",
    "    distances = np.minimum(np.linalg.norm(line_coords[None, :, :] - line_coords[:, None, :], axis=-1), np.linalg.norm(line_coords[None, :, :] - permuted_lines[:, None, :], axis=-1))\n",
    "    threshold = (image_size[0] + image_size[1]) / 80\n",
    "    mask = distances < threshold\n",
    "    indices_to_remove = np.array([np.sum(row[i+1:]) for i, row in enumerate(mask)])\n",
    "    indices_to_keep = np.where(indices_to_remove == 0)[0]\n",
    "    if line_scores is not None:\n",
    "        line_scores = np.array(line_scores)\n",
    "        return line_coords_list[indices_to_keep], line_scores[indices_to_keep]\n",
    "    return line_coords_list[indices_to_keep]\n",
    "\n",
    "def remove_small_lines(line_coords_list, image_size, line_scores=None):\n",
    "    line_coords = np.array(line_coords_list).reshape(-1, 4) # (n_lines, 4)\n",
    "    lengths = np.linalg.norm(line_coords[:, :2] - line_coords[:, 2:], axis=-1)\n",
    "    threshold = (image_size[0] + image_size[1]) / 50\n",
    "    # print(lengths)\n",
    "    mask = lengths > threshold\n",
    "    indices_to_keep = np.where(mask)[0]\n",
    "    if line_scores is not None:\n",
    "        line_scores = np.array(line_scores)\n",
    "        return line_coords_list[indices_to_keep], line_scores[indices_to_keep]\n",
    "    return line_coords_list[indices_to_keep]\n",
    "\n",
    "def remove_duplicate_arcs(line_coords_list, image_size, line_scores=None):\n",
    "    line_coords = np.array(line_coords_list).reshape(-1, 6) # (n_lines, 6)\n",
    "    permuted_lines = np.hstack((line_coords[:, 2:4],line_coords[:, 0:2], line_coords[:, 4:6]))\n",
    "    distances = np.minimum(np.linalg.norm(line_coords[None, :, :] - line_coords[:, None, :], axis=-1), np.linalg.norm(line_coords[None, :, :] - permuted_lines[:, None, :], axis=-1))\n",
    "    threshold = (image_size[0] + image_size[1]) / 50\n",
    "    mask = distances < threshold\n",
    "    indices_to_remove = np.array([np.sum(row[i+1:]) for i, row in enumerate(mask)])\n",
    "    indices_to_keep = np.where(indices_to_remove == 0)[0]\n",
    "    if line_scores is not None:\n",
    "        line_scores = np.array(line_scores)\n",
    "        return line_coords_list[indices_to_keep], line_scores[indices_to_keep]\n",
    "    return line_coords_list[indices_to_keep]\n",
    "\n",
    "def remove_arcs_on_top_of_circles(arc_coords_list, circle_coords_list, image_size, arc_scores=None): \n",
    "    arc_coords = np.array(arc_coords_list).reshape(-1, 6) # (n_arcs, 6)\n",
    "    circle_coords = np.array(circle_coords_list).reshape(-1, 3) # (n_circles, 3)\n",
    "    arc_centers = find_circle_center_arr(\n",
    "        arc_coords[:, :2],\n",
    "        arc_coords[:, 4:],\n",
    "        arc_coords[:, 2:4],\n",
    "    )\n",
    "    radii = np.linalg.norm(arc_coords[:, :2] - arc_centers, axis = 1)\n",
    "    arc_circle_coords = np.hstack((arc_centers, radii[:, None]))\n",
    "    distances = np.linalg.norm(circle_coords[None, :, :] - arc_circle_coords[:, None, :], axis=-1)\n",
    "    threshold = (image_size[0] + image_size[1]) / 80\n",
    "    # print(distances)\n",
    "    # print(threshold)\n",
    "    mask = distances < threshold\n",
    "    indices_to_remove = np.array([np.sum(row) for i, row in enumerate(mask)])\n",
    "    indices_to_keep = np.where(indices_to_remove == 0)[0]\n",
    "    if arc_scores is not None:\n",
    "        arc_scores = np.array(arc_scores)\n",
    "        return arc_coords_list[indices_to_keep], arc_scores[indices_to_keep]\n",
    "    return arc_coords_list[indices_to_keep]\n",
    "\n",
    "def remove_arcs_on_top_of_lines(arc_coords_list, line_coords_list, image_size, arc_scores=None): \n",
    "    arc_coords = np.array(arc_coords_list).reshape(-1, 6) # (n_arcs, 6)\n",
    "    line_coords = np.array(line_coords_list).reshape(-1, 4) # (n_lines, 4)\n",
    "    line_coords_w_center = np.hstack((line_coords[:, :2], line_coords[:, 2:], (line_coords[:, :2] + line_coords[:, 2:])/2))\n",
    "    line_coords_w_center_permuted = np.hstack((line_coords[:, 2:], line_coords[:, :2], (line_coords[:, :2] + line_coords[:, 2:])/2))\n",
    "    distances = np.minimum(np.linalg.norm(line_coords_w_center[None, :, :] - arc_coords[:, None, :], axis=-1), np.linalg.norm(line_coords_w_center_permuted[None, :, :] - arc_coords[:, None, :], axis=-1))\n",
    "    threshold = (image_size[0] + image_size[1]) / 50\n",
    "    mask = distances < threshold\n",
    "    indices_to_remove = np.array([np.sum(row) for i, row in enumerate(mask)])\n",
    "    indices_to_keep = np.where(indices_to_remove == 0)[0]\n",
    "    if arc_scores is not None:\n",
    "        arc_scores = np.array(arc_scores)\n",
    "        return arc_coords_list[indices_to_keep], arc_scores[indices_to_keep]\n",
    "    return arc_coords_list[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arc visualization, very clunky in python but this should work\n",
    "from matplotlib.patches import Arc\n",
    "def plot_arc(ax, arc, c='r', linewidth=2):\n",
    "    arc = arc.reshape(-1)\n",
    "    theta1, theta_mid, theta2, c_xy, diameter = get_arc_plot_params(arc)\n",
    "    if theta_mid < theta1 and theta_mid > theta2:\n",
    "        theta1, theta2 = theta2, theta1\n",
    "    to_rad = lambda x: (x * np.pi / 180) % (2 * np.pi)\n",
    "    if not is_large_arc([to_rad(theta1), to_rad(theta_mid)]):\n",
    "        arc_patch_1 = Arc(\n",
    "            c_xy,\n",
    "            diameter,\n",
    "            diameter,\n",
    "            angle=0.0,\n",
    "            theta1=theta1,\n",
    "            theta2=theta_mid,\n",
    "            fill=None,\n",
    "            color=c,\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "    else:\n",
    "        arc_patch_1 = Arc(\n",
    "            c_xy,\n",
    "            diameter,\n",
    "            diameter,\n",
    "            angle=0.0,\n",
    "            theta1=theta_mid,\n",
    "            theta2=theta1,\n",
    "            fill=None,\n",
    "            color=c,\n",
    "            # color=\"black\",\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "    ax.add_patch(arc_patch_1)\n",
    "\n",
    "    if not is_large_arc([to_rad(theta_mid), to_rad(theta2)]):\n",
    "        arc_patch_2 = Arc(\n",
    "            c_xy,\n",
    "            diameter,\n",
    "            diameter,\n",
    "            angle=0.0,\n",
    "            theta1=theta_mid,\n",
    "            theta2=theta2,\n",
    "            fill=None,\n",
    "            color=c,\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        arc_patch_2 = Arc(\n",
    "            c_xy,\n",
    "            diameter,\n",
    "            diameter,\n",
    "            angle=0.0,\n",
    "            theta1=theta2,\n",
    "            theta2=theta_mid,\n",
    "            fill=None,\n",
    "            color=c,\n",
    "            # color=\"black\",\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "    ax.add_patch(arc_patch_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Making model predictions and saving them to npz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping over images \n",
    "for image_path in tqdm(image_paths): \n",
    "    # loading image\n",
    "    im_name = Path(image_path).stem\n",
    "    # im_name_0 = 'wit2_img2_0082_230,1314,859,848'\n",
    "    # if im_name!= im_name_0:\n",
    "    #     continue\n",
    "    # print(im_name)\n",
    "    # if os.path.exists(npz_dir / f\"{im_name}.npz\") and im_name!= 'wit185_pdf193_26_188,421,557,598':\n",
    "    #     continue\n",
    "\n",
    "    # if os.path.exists(npz_dir / f\"{im_name}.npz\"):\n",
    "    #     continue\n",
    "    # if im_name not in ['wit176_man179_0151_1261,1428,471,585', 'wit205_pdf216_099_1030,1839,509,505']: \n",
    "    #     continue\n",
    "    image = Image.open(image_path).convert(\"RGB\") # load image\n",
    "    orig_img_size = image.size\n",
    "    transform = T.Compose([\n",
    "        T.RandomResize([800], max_size=1333),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    tr_img, _ = transform(image, None)\n",
    "    size = torch.Tensor([tr_img.shape[1], tr_img.shape[2]])\n",
    "    out_size = torch.Tensor([[orig_img_size[1], orig_img_size[0]]])\n",
    "\n",
    "    # output\n",
    "    output = model.cuda()(tr_img[None].cuda())   \n",
    "    output = postprocessors['param'](output, out_size.cuda(), to_xyxy=False)[0]\n",
    "\n",
    "    threshold, arc_threshold = 0.3, 0.3\n",
    "    scores = output['scores']\n",
    "    labels = output['labels']\n",
    "    boxes = output['parameters']\n",
    "    select_mask = ((scores > threshold) & (labels!=2)) | ((scores > arc_threshold) & (labels==2) )\n",
    "    labels = labels[select_mask]\n",
    "    boxes = boxes[select_mask]\n",
    "    scores = scores[select_mask]\n",
    "    pred_dict = {'parameters': boxes, 'labels': labels, 'scores': scores}\n",
    "    lines, line_scores, circles, circle_scores, arcs, arc_scores = get_outputs_per_class(pred_dict)\n",
    "\n",
    "    # some duplicate postprocessing\n",
    "    lines, line_scores = remove_duplicate_lines(lines, orig_img_size, line_scores)\n",
    "    lines, line_scores = remove_small_lines(lines, orig_img_size, line_scores)\n",
    "    circles, circle_scores = remove_duplicate_circles(circles, orig_img_size, circle_scores)\n",
    "    arcs, arc_scores = remove_duplicate_arcs(arcs, orig_img_size, arc_scores)\n",
    "    arcs, arc_scores = remove_arcs_on_top_of_circles(arcs, circles, orig_img_size, arc_scores)\n",
    "    arcs, arc_scores = remove_arcs_on_top_of_lines(arcs, lines, orig_img_size, arc_scores)\n",
    "\n",
    "    # save to npz\n",
    "    np.savez(\n",
    "        npz_dir / f\"{im_name}.npz\",\n",
    "        lines=lines,\n",
    "        line_scores=line_scores,\n",
    "        circles=circles,\n",
    "        circle_scores=circle_scores,\n",
    "        arcs=arcs,\n",
    "        arc_scores=arc_scores,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('q2x')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ad18b9cce5171a92b1ace78d675cb7cfe7b38ef1dfda11fe1bc29cba1874dd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
